{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aced63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eanthony/anaconda3/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/eanthony/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from collections import  Counter\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pyLDAvis\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from textstat import flesch_reading_ease\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams.update({'figure.figsize': [16, 12]})\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class vizzy_sentence:\n",
    "    def __init__(self, data, column, label):\n",
    "        from nltk.corpus import stopwords\n",
    "        stopwords = set(stopwords.words('english'))\n",
    "        data[column] = data[column].apply(lambda x: x.lower())\n",
    "        data['text_without_stopwords'] = data[column].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stopwords]))\n",
    "        self.data = data\n",
    "        self.column = column\n",
    "        self.label = label\n",
    "        \n",
    "        \n",
    "    def show_char_count(self):\n",
    "        '''Histogram of the length of your data column in characters'''\n",
    "        char_plot = self.data[self.column].str.len().hist()\n",
    "        return char_plot\n",
    "    \n",
    "    def show_word_count(self):\n",
    "        '''Histogram of the length of data column in words'''\n",
    "        count_plot = self.data[self.column].str.split().map(lambda x: len(x)).hist()\n",
    "        return count_plot\n",
    "    \n",
    "    def show_word_length(self):\n",
    "        '''Hist of length of words in data column in characters'''\n",
    "        len_plot = self.data[self.column].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x)).hist()\n",
    "        return len_plot\n",
    "    \n",
    "    def show_common_stopwords(self):\n",
    "        '''List of common stopwords in data'''\n",
    "        stop=set(STOPWORDS)\n",
    "        corpus=[]\n",
    "        new= self.data[self.column].str.split()\n",
    "        new=new.values.tolist()\n",
    "        corpus=[word for i in new for word in i]\n",
    "\n",
    "        from collections import defaultdict\n",
    "        dic=defaultdict(int)\n",
    "        for word in corpus:\n",
    "            if word in STOPWORDS:\n",
    "                dic[word]+=1\n",
    "        top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "        x,y=zip(*top)\n",
    "        plot = plt.bar(x,y)\n",
    "        return plot\n",
    "    \n",
    "    def show_common_words(self):\n",
    "        '''Common words in data'''\n",
    "        corpus=[]\n",
    "        new=self.data[self.column].str.split()\n",
    "        new=new.values.tolist()\n",
    "        corpus=[word for i in new for word in i]\n",
    "        counter=Counter(corpus)\n",
    "        most=counter.most_common()\n",
    "        x, y=[], []\n",
    "        for word,count in most[:40]:\n",
    "            try:\n",
    "                if (word not in STOPWORDS):\n",
    "                    x.append(word)\n",
    "                    y.append(count)\n",
    "            except:\n",
    "                x.append(word)\n",
    "                y.append(count)\n",
    "        sns.barplot(x=y,y=x)\n",
    "        \n",
    "    def show_sentiment(self):\n",
    "        '''Sentiment in data'''\n",
    "        text = self.data[self.column]\n",
    "        def polarity(text):\n",
    "            return TextBlob(text).sentiment.polarity\n",
    "        self.data['polarity_score']=self.data[self.column].apply(lambda x : polarity(x))\n",
    "        hist = self.data['polarity_score'].hist()\n",
    "        return hist\n",
    "\n",
    "    def show_sentiment_cats(self):\n",
    "        '''Plot data by sentiment (pos, neu, neg)'''\n",
    "        def polarity(text):\n",
    "            return TextBlob(text).sentiment.polarity\n",
    "        self.data['polarity_score']=self.data[self.column].apply(lambda x : polarity(x))\n",
    "        def sentiment(x):\n",
    "            if x<0:\n",
    "                return 'neg'\n",
    "            elif x==0:\n",
    "                return 'neu'\n",
    "            else:\n",
    "                return 'pos'\n",
    "        self.data['polarity']=self.data['polarity_score'].map(lambda x: sentiment(x))\n",
    "        plot = plt.bar(self.data.polarity.value_counts().index, self.data.polarity.value_counts())\n",
    "        return plot\n",
    "    \n",
    "    def show_neg_sentiment(self):\n",
    "        '''Show negative sentiment'''\n",
    "        def polarity(text):\n",
    "            return TextBlob(text).sentiment.polarity\n",
    "        self.data['polarity_score']=self.data[self.column].apply(lambda x : polarity(x))\n",
    "        def sentiment(x):\n",
    "            if x<0:\n",
    "                return 'neg'\n",
    "            elif x==0:\n",
    "                return 'neu'\n",
    "            else:\n",
    "                return 'pos'\n",
    "        self.data['polarity']=self.data['polarity_score'].map(lambda x: sentiment(x))\n",
    "        results = self.data[self.data['polarity']=='neg'][self.column].head(5)\n",
    "        return results\n",
    "    \n",
    "    def show_pos_sentiment(self):\n",
    "        '''Show positive sentiment'''\n",
    "        def polarity(text):\n",
    "            return TextBlob(text).sentiment.polarity\n",
    "        self.data['polarity_score']=self.data[self.column].apply(lambda x : polarity(x))\n",
    "        def sentiment(x):\n",
    "            if x<0:\n",
    "                return 'neg'\n",
    "            elif x==0:\n",
    "                return 'neu'\n",
    "            else:\n",
    "                return 'pos'\n",
    "        self.data['polarity']=self.data['polarity_score'].map(lambda x: sentiment(x))\n",
    "        results = self.data[self.data['polarity']=='pos'][self.column].head(5)\n",
    "        return results\n",
    "    \n",
    "    def show_flesch_kincaid(self):\n",
    "        '''show flesch kincaid score'''\n",
    "        hist = self.data[self.column].apply(lambda x : flesch_reading_ease(x)).hist()\n",
    "        return hist\n",
    "    \n",
    "    def show_bi_grams(self):\n",
    "        '''show most common bi-grams'''\n",
    "        corpus=[]\n",
    "        new=self.data[self.column].str.split()\n",
    "        new=new.values.tolist()\n",
    "        corpus=[word for i in new for word in i]\n",
    "        def get_top_ngram(corpus, n=None):\n",
    "            vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) \n",
    "                          for word, idx in vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "            return words_freq[:10]\n",
    "\n",
    "        top_n_bigrams=get_top_ngram(self.data[self.column],2)[:10]\n",
    "        x,y=map(list,zip(*top_n_bigrams))\n",
    "        plot = sns.barplot(x=y,y=x)\n",
    "        return plot\n",
    "        \n",
    "    def show_tri_grams(self):\n",
    "        '''show most common tri-grams'''\n",
    "        corpus=[]\n",
    "        new=self.data[self.column].str.split()\n",
    "        new=new.values.tolist()\n",
    "        corpus=[word for i in new for word in i]\n",
    "        def get_top_ngram(corpus, n=None):\n",
    "            vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "            bag_of_words = vec.transform(corpus)\n",
    "            sum_words = bag_of_words.sum(axis=0) \n",
    "            words_freq = [(word, sum_words[0, idx]) \n",
    "                          for word, idx in vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "            return words_freq[:10]\n",
    "\n",
    "        top_n_bigrams=get_top_ngram(self.data[self.column],3)[:10]\n",
    "        x,y=map(list,zip(*top_n_bigrams))\n",
    "        plot = sns.barplot(x=y,y=x)\n",
    "        return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vizzy_token:\n",
    "    def __init__(self, data, column):\n",
    "        self.data = data\n",
    "        self.column = column\n",
    "        \n",
    "    def show_labels_count(self):\n",
    "        '''show count of each label'''\n",
    "        labels = self.data[self.label]\n",
    "        counter = Counter(labels)\n",
    "        for label, count in counter:\n",
    "            x.append(label)\n",
    "            y.append(count)\n",
    "        plot = sns.barplot(x=y,y=x)\n",
    "        return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2dfa915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"SpaCy is a popular library for NLP in Python. Another popular library is NLTK\"\n",
    "doc = nlp(text)\n",
    "\n",
    "data = []\n",
    "for token in doc:\n",
    "    data.append({\"Token\": token.text, \"Lemma\": token.lemma_, \"POS\": token.pos_, \"ENT\": token.ent_type_})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "44f29df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vizzy_doc:\n",
    "    def __init__(self, data, column1, column2=None, column3=None, column4=None, column5=None):\n",
    "        self.data = data\n",
    "        self.column1 = column1\n",
    "        self.column2 = column2\n",
    "        self.column3 = column3\n",
    "        self.column4 = column4\n",
    "        self.column5 = column5\n",
    "        \n",
    "    def show_doc_stats(self):\n",
    "        def counter(data, column):\n",
    "            return data[column].nunique()\n",
    "            \n",
    "        docs = max(idx for idx, other in self.data.iterrows())\n",
    "        print(\"Here is your dataframe summary:\")\n",
    "        print(\"\\n\")\n",
    "        print(\"Total number of documents: {}\".format(docs))\n",
    "        print(\"Total number of {}: {}\".format(str(self.column1), (counter(self.data, self.column1))))\n",
    "        if self.column2 != None:\n",
    "            print(\"Total number of {}: {}\".format(str(self.column2), (counter(self.data, self.column2))))\n",
    "        else:\n",
    "            pass\n",
    "        if self.column3 != None:\n",
    "             print(\"Total number of {}: {}\".format(str(self.column3), (counter(self.data, self.column3))))\n",
    "        else:\n",
    "            pass\n",
    "        if self.column4 != None:\n",
    "             print(\"Total number of {}: {}\".format(str(self.column4), (counter(self.data, self.column4))))\n",
    "        else:\n",
    "            pass\n",
    "        if self.column5 != None:\n",
    "             print(\"Total number of {}: {}\".format(str(self.column5), (counter(self.data, self.column5))))\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def show_most_common(self):\n",
    "        def counter(data, column):\n",
    "            return data[column].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "27265499",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = vizzy_doc(df, \"POS\", \"ENT\", \"Lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "226dc0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your dataframe summary:\n",
      "\n",
      "\n",
      "Total number of documents: 14\n",
      "Total number of POS: 7\n",
      "Total number of ENT: 2\n",
      "Total number of Lemma: 12\n"
     ]
    }
   ],
   "source": [
    "viz.show_doc_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a252f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
